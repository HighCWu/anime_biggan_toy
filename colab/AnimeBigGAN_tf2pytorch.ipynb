{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnimeBigGAN_tf2pytorch.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HighCWu/anime_biggan_toy/blob/main/colab/AnimeBigGAN_tf2pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlVZhUmS6XIj"
      },
      "source": [
        "## Download Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtKvvSf16gPI"
      },
      "source": [
        "!rsync --verbose --progress rsync://176.9.41.242:873/biggan/2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250.tar.xz ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5epbEzb46iLl"
      },
      "source": [
        "!tar -xf 2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250.tar.xz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuKVT_E26bsI"
      },
      "source": [
        "## Restore Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "799hweZO5_qV"
      },
      "source": [
        "!pip install mock\n",
        "!git clone https://github.com/HighCWu/compare_gan\n",
        "!cd compare_gan && git checkout easyhub\n",
        "!cd compare_gan && pip install -e .\n",
        "!cp ./2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250 ./compare_gan/ -r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjrDbPjNHS_L"
      },
      "source": [
        "import os\n",
        "os.chdir('compare_gan')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEUkwMqLIMn0"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUJgSBKyDAGy"
      },
      "source": [
        "# ModularGAN extend build_graph fn\n",
        "import tensorflow as tf\n",
        "from compare_gan.gans.modular_gan import ModularGAN\n",
        "\n",
        "\n",
        "def build_graph(self, model=None):\n",
        "    batch_size = None\n",
        "    is_training = False\n",
        "    y_gen, y_disc = None, None\n",
        "    inputs_gen, inputs_disc = {}, {}\n",
        "    outputs_gen, outputs_disc = {}, {}\n",
        "    inputs_gen[\"z\"] = None if model=='disc' else tf.placeholder(\n",
        "        shape=(batch_size, self._z_dim),\n",
        "        dtype=tf.float32,\n",
        "        name=\"z_for_eval\"\n",
        "    )\n",
        "    inputs_disc[\"images\"] = None if model=='gen' else tf.placeholder(\n",
        "        shape=[batch_size] + list(self._dataset.image_shape),\n",
        "        dtype=tf.float32,\n",
        "        name=\"images_for_eval\"\n",
        "    )\n",
        "    if self.conditional:\n",
        "        inputs_gen[\"labels\"] = None if model=='disc' else tf.placeholder(\n",
        "            shape=(batch_size,),\n",
        "            dtype=tf.int32,\n",
        "            name=\"labels_for_gen_eval\"\n",
        "        )\n",
        "        y_gen = None if model=='disc' else self._get_one_hot_labels(inputs_gen[\"labels\"])\n",
        "        inputs_disc[\"labels\"] = None if model=='gen' else tf.placeholder(\n",
        "            shape=(batch_size,),\n",
        "            dtype=tf.int32,\n",
        "            name=\"labels_for_disc_eval\"\n",
        "        )\n",
        "        y_disc = None if model=='gen' else self._get_one_hot_labels(inputs_disc[\"labels\"])\n",
        "    else:\n",
        "      y_gen, y_disc = None, None\n",
        "\n",
        "    outputs_disc[\"prediction\"], _, _ = (None,None,None) if model=='gen' else self.discriminator(\n",
        "        inputs_disc[\"images\"], y=y_disc, is_training=is_training\n",
        "    )\n",
        "\n",
        "    z = inputs_gen[\"z\"]\n",
        "    generated = None if model=='disc' else self.generator(z=z, y=y_gen, is_training=is_training)\n",
        "    if self._g_use_ema and model != 'disc':\n",
        "        g_vars = [var for var in tf.trainable_variables()\n",
        "              if \"generator\" in var.name]\n",
        "        ema = tf.train.ExponentialMovingAverage(decay=self._ema_decay)\n",
        "        # Create the variables that will be loaded from the checkpoint.\n",
        "        ema.apply(g_vars)\n",
        "        def ema_getter(getter, name, *args, **kwargs):\n",
        "            var = getter(name, *args, **kwargs)\n",
        "            ema_var = ema.average(var)\n",
        "            if ema_var is None:\n",
        "                var_names_without_ema = {\"u_var\", \"accu_mean\", \"accu_variance\",\n",
        "                              \"accu_counter\", \"update_accus\"}\n",
        "                if name.split(\"/\")[-1] not in var_names_without_ema:\n",
        "                    print(\"Could not find EMA variable for %s.\", name)\n",
        "                return var\n",
        "            return ema_var\n",
        "        with tf.variable_scope(\"\", values=[z, y_gen], reuse=True, custom_getter=ema_getter):\n",
        "            ema_generated = self.generator(z, y=y_gen, is_training=is_training)\n",
        "            if not is_training:\n",
        "                generated = ema_generated\n",
        "    outputs_gen[\"generated\"] = None if model=='disc' else generated\n",
        "    return {\n",
        "        \"gen\": {\n",
        "            \"inputs\": inputs_gen, \n",
        "            \"outputs\": outputs_gen\n",
        "        },\n",
        "        \"disc\": {\n",
        "            \"inputs\": inputs_disc,\n",
        "            \"outputs\": outputs_disc\n",
        "        }\n",
        "    }\n",
        "ModularGAN.build_graph = build_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UCcxAoSEP6z"
      },
      "source": [
        "import os\n",
        "import gin\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from compare_gan import main, runner_lib, datasets\n",
        "from compare_gan.gans import utils, modular_gan\n",
        "from compare_gan.gans.modular_gan import ModularGAN\n",
        "\n",
        "os.environ[\"NUM_CORES\"] = '8'\n",
        "gin.parse_config_file('example_configs/bigrun40.gin')\n",
        "gin.bind_parameter(\"standardize_batch.use_cross_replica_mean\", False)\n",
        "gin.bind_parameter(\"spectral_norm.save_in_checkpoint\", False)\n",
        "src_model_path = '2020-05-18-spresser-biggan-256px-danbooruplus-run39-607250/'\n",
        "\n",
        "use_ema = True\n",
        "\n",
        "class FakeDataset:\n",
        "    num_classes = 1000\n",
        "    random_labels = True\n",
        "    image_shape = (256, 256, 3)\n",
        "\n",
        "\n",
        "model = ModularGAN(FakeDataset, {\n",
        "        \"architecture\": \"resnet_biggan_arch\",\n",
        "        \"z_dim\": 140,\n",
        "        \"lambda\": 1,\n",
        "    }, src_model_path, g_use_ema=use_ema\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT1uTikUztUU"
      },
      "source": [
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from compare_gan.architectures import arch_ops\n",
        "arch_ops.use_assign_forbidden = False\n",
        "\n",
        "os.makedirs('accu_samples', exist_ok=True)\n",
        "\n",
        "batch_size = 8\n",
        "num_accu_steps = 8 # a few steps and accu all levels together\n",
        "checkpoint_path = os.path.join('anime-biggan-256px-run39-607250-tmp', \"model.ckpt\")\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "inout_nodes = model.build_graph()\n",
        "inout_gen, inout_disc = inout_nodes[\"gen\"], inout_nodes[\"disc\"]\n",
        "init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
        "sess.run(init_op)\n",
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, src_model_path + 'model.ckpt-607250')\n",
        "update_accu_switches = [v for v in tf.global_variables()\n",
        "                if \"accu/update_accus\" in v.name]\n",
        "def run_model():\n",
        "    z = rng.randn(batch_size, model._z_dim).astype(np.float32)\n",
        "    if not model.conditional:\n",
        "        _z = inout_gen['inputs']['z']\n",
        "        images = sess.run(inout_gen['outputs']['generated'], feed_dict={_z: z})\n",
        "    else:\n",
        "        y = rng.randint(model._dataset.num_classes, size=(batch_size, )).astype(np.int32)\n",
        "        _z = inout_gen['inputs']['z']\n",
        "        _y_gen = inout_gen['inputs']['labels']\n",
        "        images = sess.run(inout_gen['outputs']['generated'], feed_dict={_z: z, _y_gen: y})\n",
        "    return images\n",
        "for j, update_accu in enumerate(update_accu_switches):\n",
        "    sess.run(tf.assign(update_accu, 1))\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "for i in range(num_accu_steps):\n",
        "    images = run_model()\n",
        "    dst_filename = f'accu_samples/batchsize_{batch_size}.png'\n",
        "    image = Image.fromarray(np.uint8(images.transpose((1,0,2,3)).reshape((256,-1,3)).clip(0,1) * 255))\n",
        "    image.save(f'accu_samples/batchsize_{batch_size}_accu_{str(i+1).zfill(5)}.png')\n",
        "    print(f'Updating BN accumulators {str(i+1).zfill(5)}/{str(num_accu_steps).zfill(5)} steps.')\n",
        "\n",
        "for j, update_accu in enumerate(update_accu_switches):\n",
        "    sess.run(tf.assign(update_accu, 0))\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "images = run_model()\n",
        "dst_filename = f'accu_samples/batchsize_{batch_size}.png'\n",
        "image = Image.fromarray(np.uint8(images.transpose((1,0,2,3)).reshape((256,-1,3)).clip(0,1) * 255))\n",
        "image.save(dst_filename)\n",
        "print('Done updating BN accumulators.')\n",
        "\n",
        "\n",
        "for tensor in [tensor for op in sess.graph.get_operations() for tensor in op.values()]:\n",
        "    if 'generator_1' in tensor.name: # ema\n",
        "        print(tensor.name, tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tensor in [tensor for op in sess.graph.get_operations() for tensor in op.values()]:\n",
        "  if 'generator' in tensor.name:\n",
        "    print(tensor.name, tensor.shape)"
      ],
      "metadata": {
        "id": "sMDnmqKF-4SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFHub Model to PyTorch Model"
      ],
      "metadata": {
        "id": "MwV1HxhFfSxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var_list = []\n",
        "for var in tf.global_variables():\n",
        "    if 'discriminator' not in var.name:\n",
        "        val = sess.run(var)\n",
        "        if '/ExponentialMovingAverage' in var.name:\n",
        "            name = ''.join(var.name.split('/ExponentialMovingAverage'))\n",
        "            for i, weights in enumerate(var_list):\n",
        "                if weights[0] == name:\n",
        "                    weights[1] = val\n",
        "        else:\n",
        "            var_list.append([var.name, val])\n",
        "\n",
        "idx = 0\n",
        "var_list_ids = []\n",
        "for var in tf.local_variables():\n",
        "    if 'discriminator' not in var.name and \\\n",
        "      '/u_var' in var.name and \\\n",
        "      'bias' not in var.name and \\\n",
        "      'accu_' not in var.name and \\\n",
        "      'embed_y' not in var.name and \\\n",
        "      'final_norm' not in var.name:\n",
        "        while var.name.split('/u_var')[0] + ':0' != var_list[idx][0] and var.name.split('/u_var')[0] != var_list[idx][0]:\n",
        "            idx = idx + 1\n",
        "        var_list_ids.append([idx, [var.name, sess.run(var)]])\n",
        "for (idx, var) in var_list_ids[::-1]:\n",
        "    var_list.insert(idx + 1, var)\n",
        "\n",
        "for weights in var_list:\n",
        "  print(weights[0], weights[1].shape)\n",
        "\n",
        "tf_weights = var_list\n",
        " \n",
        "def tf_filter(x):\n",
        "  if 'accu/update_accus:0' in x[0]:\n",
        "    return False\n",
        "  return True\n",
        " \n",
        "tf_weights = list(filter(tf_filter, tf_weights))"
      ],
      "metadata": {
        "id": "Y9kBEWgOfoGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Generator and Discriminator model\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import Parameter\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "def l2_normalize(v, dim=None, eps=1e-12):\n",
        "    return v / (v.norm(dim=dim, keepdim=True) + eps)\n",
        "    \n",
        " \n",
        "def unpool(value):\n",
        "    \"\"\"Unpooling operation.\n",
        "    N-dimensional version of the unpooling operation from\n",
        "    https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n",
        "    Taken from: https://github.com/tensorflow/tensorflow/issues/2169\n",
        "    Args:\n",
        "        value: a Tensor of shape [b, d0, d1, ..., dn, ch]\n",
        "        name: name of the op\n",
        "    Returns:\n",
        "        A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\n",
        "    \"\"\"\n",
        "    value = torch.Tensor.permute(value, [0,2,3,1])\n",
        "    sh = list(value.shape)\n",
        "    dim = len(sh[1:-1])\n",
        "    out = (torch.reshape(value, [-1] + sh[-dim:]))\n",
        "    for i in range(dim, 0, -1):\n",
        "        out = torch.cat([out, torch.zeros_like(out)], i)\n",
        "    out_size = [-1] + [s * 2 for s in sh[1:-1]] + [sh[-1]]\n",
        "    out = torch.reshape(out, out_size)\n",
        "    out = torch.Tensor.permute(out, [0,3,1,2])\n",
        "    return out\n",
        " \n",
        " \n",
        "class BatchNorm2d(nn.BatchNorm2d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.initialized = False\n",
        "        self.accumulating = False\n",
        "        self.accumulated_mean = Parameter(torch.zeros(args[0]), requires_grad=False)\n",
        "        self.accumulated_var = Parameter(torch.zeros(args[0]), requires_grad=False)\n",
        "        self.accumulated_counter = Parameter(torch.zeros(1)+1e-12, requires_grad=False)\n",
        " \n",
        "    def forward(self, inputs, *args, **kwargs):\n",
        "        if not self.initialized:\n",
        "            self.check_accumulation()\n",
        "            self.set_initialized(True)\n",
        "        if self.accumulating:\n",
        "            self.eval()\n",
        "            with torch.no_grad():\n",
        "                axes = [0] + ([] if len(inputs.shape) == 2 else list(range(2,len(inputs.shape))))\n",
        "                _mean = torch.mean(inputs, axes, keepdim=True)\n",
        "                mean = torch.mean(inputs, axes, keepdim=False)\n",
        "                var = torch.mean((inputs-_mean)**2, axes)\n",
        "                self.accumulated_mean.copy_(self.accumulated_mean + mean)\n",
        "                self.accumulated_var.copy_(self.accumulated_var + var)\n",
        "                self.accumulated_counter.copy_(self.accumulated_counter + 1)\n",
        "                _mean = self.running_mean*1.0\n",
        "                _variance = self.running_var*1.0\n",
        "                self._mean.copy_(self.accumulated_mean / self.accumulated_counter)\n",
        "                self._variance.copy_(self.accumulated_var / self.accumulated_counter)\n",
        "                out = super().forward(inputs, *args, **kwargs)\n",
        "                self.running_mean.copy_(_mean)\n",
        "                self.running_var.copy_(_variance)\n",
        "                return out\n",
        "        out = super().forward(inputs, *args, **kwargs)\n",
        "        return out\n",
        " \n",
        "    def check_accumulation(self):\n",
        "        if self.accumulated_counter.detach().cpu().numpy().mean() > 1-1e-12:\n",
        "            self.running_mean.copy_(self.accumulated_mean / self.accumulated_counter)\n",
        "            self.running_var.copy_(self.accumulated_var / self.accumulated_counter)\n",
        "            return True\n",
        "        return False\n",
        " \n",
        "    def clear_accumulated(self):\n",
        "        self.accumulated_mean.copy_(self.accumulated_mean*0.0)\n",
        "        self.accumulated_var.copy_(self.accumulated_var*0.0)\n",
        "        self.accumulated_counter.copy_(self.accumulated_counter*0.0+1e-2)\n",
        " \n",
        "    def set_accumulating(self, status=True):\n",
        "        if status:\n",
        "            self.accumulating = True\n",
        "        else:\n",
        "            self.accumulating = False\n",
        " \n",
        "    def set_initialized(self, status=False):\n",
        "        if not status:\n",
        "            self.initialized = False\n",
        "        else:\n",
        "            self.initialized = True\n",
        " \n",
        "\n",
        "class SpectralNorm(nn.Module):\n",
        "    def __init__(self, module, name='weight', power_iterations=2):\n",
        "        super().__init__()\n",
        "        self.module = module\n",
        "        self.name = name\n",
        "        self.power_iterations = power_iterations\n",
        "        if not self._made_params():\n",
        "            self._make_params()\n",
        " \n",
        "    def _update_u(self):\n",
        "        w = self.weight\n",
        "        u = self.weight_u\n",
        " \n",
        "        if len(w.shape) == 4:\n",
        "            _w = torch.Tensor.permute(w, [2,3,1,0])\n",
        "            _w = torch.reshape(_w, [-1, _w.shape[-1]])\n",
        "        elif isinstance(self.module, nn.Linear) or isinstance(self.module, nn.Embedding):\n",
        "            _w = torch.Tensor.permute(w, [1,0])\n",
        "            _w = torch.reshape(_w, [-1, _w.shape[-1]])\n",
        "        else:\n",
        "            _w = torch.reshape(w, [-1, w.shape[-1]])\n",
        "            _w = torch.reshape(_w, [-1, _w.shape[-1]])\n",
        "        singular_value = \"left\" if _w.shape[0] <= _w.shape[1] else \"right\"\n",
        "        norm_dim = 0 if _w.shape[0] <= _w.shape[1] else 1\n",
        "        for _ in range(self.power_iterations):\n",
        "            if singular_value == \"left\":\n",
        "                v = l2_normalize(torch.matmul(_w.t(), u), dim=norm_dim)\n",
        "                u = l2_normalize(torch.matmul(_w, v), dim=norm_dim)\n",
        "            else:\n",
        "                v = l2_normalize(torch.matmul(u, _w.t()), dim=norm_dim)\n",
        "                u = l2_normalize(torch.matmul(v, _w), dim=norm_dim)\n",
        " \n",
        "        if singular_value == \"left\":\n",
        "            sigma = torch.matmul(torch.matmul(u.t(), _w), v)\n",
        "        else:\n",
        "            sigma = torch.matmul(torch.matmul(v, _w), u.t())\n",
        "        _w = w / sigma.detach()\n",
        "        setattr(self.module, self.name, _w)\n",
        "        self.weight_u.copy_(u.detach())\n",
        " \n",
        "    def _made_params(self):\n",
        "        try:\n",
        "            self.weight\n",
        "            self.weight_u\n",
        "            return True\n",
        "        except AttributeError:\n",
        "            return False\n",
        " \n",
        "    def _make_params(self):\n",
        "        w = getattr(self.module, self.name)\n",
        " \n",
        "        if len(w.shape) == 4:\n",
        "            _w = torch.Tensor.permute(w, [2,3,1,0])\n",
        "            _w = torch.reshape(_w, [-1, _w.shape[-1]])\n",
        "        elif isinstance(self.module, nn.Linear) or isinstance(self.module, nn.Embedding):\n",
        "            _w = torch.Tensor.permute(w, [1,0])\n",
        "            _w = torch.reshape(_w, [-1, _w.shape[-1]])\n",
        "        else:\n",
        "            _w = torch.reshape(w, [-1, w.shape[-1]])\n",
        "        singular_value = \"left\" if _w.shape[0] <= _w.shape[1] else \"right\"\n",
        "        norm_dim = 0 if _w.shape[0] <= _w.shape[1] else 1\n",
        "        u_shape = (_w.shape[0], 1) if singular_value == \"left\" else (1, _w.shape[-1])\n",
        "        \n",
        "        u = Parameter(w.data.new(*u_shape).normal_(0, 1), requires_grad=False)\n",
        "        u.copy_(l2_normalize(u, dim=norm_dim).detach())\n",
        " \n",
        "        del self.module._parameters[self.name]\n",
        "        self.weight = w\n",
        "        self.weight_u = u\n",
        " \n",
        "    def forward(self, *args, **kwargs):\n",
        "        self._update_u()\n",
        "        return self.module.forward(*args, **kwargs)\n",
        "    \n",
        "    \n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_dim, activation=torch.relu):\n",
        "        super().__init__()\n",
        "        self.chanel_in = in_dim\n",
        "        self.activation = activation\n",
        "    \n",
        "        self.theta = SpectralNorm(nn.Conv2d(in_dim, in_dim // 8, 1, bias=False))\n",
        "        self.phi = SpectralNorm(nn.Conv2d(in_dim, in_dim // 8, 1, bias=False))\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.g = SpectralNorm(nn.Conv2d(in_dim, in_dim // 2, 1, bias=False))\n",
        "        self.o_conv = SpectralNorm(nn.Conv2d(in_dim // 2, in_dim, 1, bias=False))\n",
        "        self.gamma = Parameter(torch.zeros(1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        m_batchsize, C, width, height = x.shape\n",
        "        N = height * width\n",
        "    \n",
        "        theta = self.theta(x)\n",
        "        phi = self.phi(x)\n",
        "        phi = self.pool(phi)\n",
        "        phi = torch.reshape(phi,(m_batchsize, -1, N // 4))\n",
        "        theta = torch.reshape(theta,(m_batchsize, -1, N))\n",
        "        theta = torch.Tensor.permute(theta,(0, 2, 1))\n",
        "        attention = torch.softmax(torch.bmm(theta, phi), -1)\n",
        "        g = self.g(x)\n",
        "        g = torch.reshape(self.pool(g),(m_batchsize, -1, N // 4))\n",
        "        attn_g = torch.reshape(torch.bmm(g, torch.Tensor.permute(attention,(0, 2, 1))),(m_batchsize, -1, width, height))\n",
        "        out = self.o_conv(attn_g)\n",
        "        return self.gamma * out + x\n",
        " \n",
        " \n",
        "class ConditionalBatchNorm2d(nn.Module):\n",
        "    def __init__(self, num_features, num_classes, eps=1e-5, momentum=0.1):\n",
        "        super().__init__()\n",
        "        self.bn_in_cond = BatchNorm2d(num_features, affine=False, eps=eps, momentum=momentum)\n",
        "        self.gamma_embed = SpectralNorm(nn.Linear(num_classes, num_features, bias=False))\n",
        "        self.beta_embed = SpectralNorm(nn.Linear(num_classes, num_features, bias=False))\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        out = self.bn_in_cond(x)\n",
        "\n",
        "        if isinstance(y, list):\n",
        "            gamma, beta = y\n",
        "            out = torch.reshape(gamma, (gamma.shape[0], -1, 1, 1)) * out + torch.reshape(beta, (beta.shape[0], -1, 1, 1))\n",
        "            return out\n",
        "\n",
        "        gamma = self.gamma_embed(y)\n",
        "        # gamma = gamma + 1\n",
        "        beta = self.beta_embed(y)\n",
        "        out = torch.reshape(gamma, (gamma.shape[0], -1, 1, 1)) * out + torch.reshape(beta, (beta.shape[0], -1, 1, 1))\n",
        "        return out\n",
        " \n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channel,\n",
        "        out_channel,\n",
        "        kernel_size=[3, 3],\n",
        "        padding=1,\n",
        "        stride=1,\n",
        "        n_class=None,\n",
        "        conditional=True,\n",
        "        activation=torch.relu,\n",
        "        upsample=True,\n",
        "        downsample=False,\n",
        "        z_dim=128,\n",
        "        use_attention=False,\n",
        "        skip_proj=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "    \n",
        "        if conditional:\n",
        "            self.cond_norm1 = ConditionalBatchNorm2d(in_channel, z_dim)\n",
        "    \n",
        "        self.conv0 = SpectralNorm(\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding)\n",
        "        )\n",
        "    \n",
        "        if conditional:\n",
        "            self.cond_norm2 = ConditionalBatchNorm2d(out_channel, z_dim)\n",
        "    \n",
        "        self.conv1 = SpectralNorm(\n",
        "            nn.Conv2d(out_channel, out_channel, kernel_size, stride, padding)\n",
        "        )\n",
        "    \n",
        "        self.skip_proj = False\n",
        "        if skip_proj is not True and (upsample or downsample):\n",
        "            self.conv_sc = SpectralNorm(nn.Conv2d(in_channel, out_channel, 1, 1, 0))\n",
        "            self.skip_proj = True\n",
        "    \n",
        "        if use_attention:\n",
        "            self.attention = SelfAttention(out_channel)\n",
        "    \n",
        "        self.upsample = upsample\n",
        "        self.downsample = downsample\n",
        "        self.activation = activation\n",
        "        self.conditional = conditional\n",
        "        self.use_attention = use_attention\n",
        "    \n",
        "    def forward(self, input, condition=None):\n",
        "        out = input\n",
        "    \n",
        "        if self.conditional:\n",
        "            out = self.cond_norm1(out, condition if not isinstance(condition, list) else condition[0])\n",
        "        out = self.activation(out)\n",
        "        if self.upsample:\n",
        "            out = unpool(out) # out = F.interpolate(out, scale_factor=2)\n",
        "        out = self.conv0(out)\n",
        "        if self.conditional:\n",
        "            out = self.cond_norm2(out, condition if not isinstance(condition, list) else condition[1])\n",
        "        out = self.activation(out)\n",
        "        out = self.conv1(out)\n",
        "        \n",
        "        if self.downsample:\n",
        "            out = F.avg_pool2d(out, 2, 2)\n",
        "    \n",
        "        if self.skip_proj:\n",
        "            skip = input\n",
        "            if self.upsample:\n",
        "                skip = unpool(skip) # skip = F.interpolate(skip, scale_factor=2)\n",
        "            skip = self.conv_sc(skip)\n",
        "            if self.downsample:\n",
        "                skip = F.avg_pool2d(skip, 2, 2)\n",
        "            out = out + skip\n",
        "        else:\n",
        "            skip = input\n",
        "    \n",
        "        if self.use_attention:\n",
        "            out = self.attention(out)\n",
        "    \n",
        "        return out\n",
        " \n",
        " \n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, code_dim=128, n_class=1000, chn=96, blocks_with_attention=\"B4\", resolution=512):\n",
        "        super().__init__()\n",
        "    \n",
        "        def GBlock(in_channel, out_channel, n_class, z_dim, use_attention):\n",
        "            return ResBlock(in_channel, out_channel, n_class=n_class, z_dim=z_dim, use_attention=use_attention)\n",
        "    \n",
        "        self.embed_y = nn.Linear(n_class, 128, bias=False)\n",
        "    \n",
        "        self.chn = chn\n",
        "        self.resolution = resolution \n",
        "        self.blocks_with_attention = set(blocks_with_attention.split(\",\")) \n",
        "        self.blocks_with_attention.discard('')\n",
        "    \n",
        "        gblock = []\n",
        "        in_channels, out_channels = self.get_in_out_channels()\n",
        "        self.num_split = len(in_channels) + 1\n",
        "    \n",
        "        z_dim = code_dim//self.num_split + 128\n",
        "        self.noise_fc = SpectralNorm(nn.Linear(code_dim//self.num_split, 4 * 4 * in_channels[0]))\n",
        "    \n",
        "        self.sa_ids = [int(s.split('B')[-1]) for s in self.blocks_with_attention]\n",
        "    \n",
        "        for i, (nc_in, nc_out) in enumerate(zip(in_channels, out_channels)):\n",
        "            gblock.append(GBlock(nc_in, nc_out, n_class=n_class, z_dim=z_dim, use_attention=(i+1) in self.sa_ids))\n",
        "        self.blocks = nn.ModuleList(gblock)\n",
        "    \n",
        "        self.output_layer_bn = BatchNorm2d(1 * chn, eps=1e-5)\n",
        "        self.output_layer_conv = SpectralNorm(nn.Conv2d(1 * chn, 3, [3, 3], padding=1))\n",
        " \n",
        "    def get_in_out_channels(self):\n",
        "        resolution = self.resolution\n",
        "        if resolution == 1024:\n",
        "            channel_multipliers = [16, 16, 8, 8, 4, 2, 1, 1, 1]\n",
        "        elif resolution == 512:\n",
        "            channel_multipliers = [16, 16, 8, 8, 4, 2, 1, 1]\n",
        "        elif resolution == 256:\n",
        "            channel_multipliers = [16, 16, 8, 8, 4, 2, 1]\n",
        "        elif resolution == 128:\n",
        "            channel_multipliers = [16, 16, 8, 4, 2, 1]\n",
        "        elif resolution == 64:\n",
        "            channel_multipliers = [16, 16, 8, 4, 2]\n",
        "        elif resolution == 32:\n",
        "            channel_multipliers = [4, 4, 4, 4]\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported resolution: {}\".format(resolution))\n",
        "        in_channels = [self.chn * c for c in channel_multipliers[:-1]]\n",
        "        out_channels = [self.chn * c for c in channel_multipliers[1:]]\n",
        "        return in_channels, out_channels\n",
        " \n",
        "    def forward(self, input, class_id):\n",
        "        codes = torch.chunk(input, self.num_split, 1)\n",
        "        class_emb = self.embed_y(class_id)  # 128\n",
        "        out = self.noise_fc(codes[0])\n",
        "        out = torch.Tensor.permute(torch.reshape(out,(out.shape[0], 4, 4, -1)),(0, 3, 1, 2))\n",
        "        for i, (code, gblock) in enumerate(zip(codes[1:], self.blocks)):\n",
        "            condition = torch.cat([code, class_emb], 1)\n",
        "            out = gblock(out, condition)\n",
        "    \n",
        "        out = self.output_layer_bn(out)\n",
        "        out = torch.relu(out)\n",
        "        out = self.output_layer_conv(out)\n",
        "        \n",
        "        return (torch.tanh(out) + 1) / 2\n",
        "\n",
        "    def forward_w(self, ws):\n",
        "        out = self.noise_fc(ws[0])\n",
        "        out = torch.Tensor.permute(torch.reshape(out,(out.shape[0], 4, 4, -1)),(0, 3, 1, 2))\n",
        "        for i, (w, gblock) in enumerate(zip(ws[1:], self.blocks)):\n",
        "            out = gblock(out, w)\n",
        "    \n",
        "        out = self.output_layer_bn(out)\n",
        "        out = torch.relu(out)\n",
        "        out = self.output_layer_conv(out)\n",
        "        \n",
        "        return (torch.tanh(out) + 1) / 2\n",
        "\n",
        "    def forward_wp(self, z0, gammas, betas):\n",
        "        out = self.noise_fc(z0)\n",
        "        out = torch.Tensor.permute(torch.reshape(out,(out.shape[0], 4, 4, -1)),(0, 3, 1, 2))\n",
        "        for i, (gamma, beta, gblock) in enumerate(zip(gammas, betas, self.blocks)):\n",
        "            out = gblock(out, [[gamma[0], beta[0]], [gamma[1], beta[1]]])\n",
        "    \n",
        "        out = self.output_layer_bn(out)\n",
        "        out = torch.relu(out)\n",
        "        out = self.output_layer_conv(out)\n",
        "        \n",
        "        return (torch.tanh(out) + 1) / 2\n"
      ],
      "metadata": {
        "id": "nUGJFMy5niDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(code_dim=140, n_class=1000, chn=96, blocks_with_attention=\"B5\", resolution=256).cuda()\n",
        "\n",
        "def pt_filter(x):\n",
        "  if 'weight_v' in x[0] or '._mean' in x[0] or '._variance' in x[0] \\\n",
        "     or'.bn_in_cond.weight' in x[0] or '.bn_in_cond.bias' in x[0]:\n",
        "    return False\n",
        "  return True\n",
        " \n",
        "_pt_params = list(filter(pt_filter, generator.named_parameters()))\n",
        "pt_params = []\n",
        "for i, params in enumerate(_pt_params):\n",
        "  b_continue = False\n",
        "  for j in range(6):\n",
        "    if 'attention.gamma' in _pt_params[i-j][0]:\n",
        "      pt_params.append(_pt_params[i+1])\n",
        "      b_continue = True\n",
        "  if b_continue:\n",
        "    continue\n",
        "  if 'attention.gamma' in _pt_params[i-6][0]:\n",
        "    pt_params.append(_pt_params[i-6])\n",
        "    continue\n",
        "  if 'output_layer.0.weight' in params[0]:\n",
        "    pt_params.append(_pt_params[i+1])\n",
        "    continue\n",
        "  if 'output_layer.0.bias' in params[0]:\n",
        "    pt_params.append(_pt_params[i-1])\n",
        "    continue\n",
        "  pt_params.append(params)\n",
        " \n",
        "_pt_params = pt_params\n",
        "pt_params = [param for param in _pt_params]\n",
        "pt_params[-8] = _pt_params[-6]\n",
        "pt_params[-7] = _pt_params[-5]\n",
        "pt_params[-6] = _pt_params[-4]\n",
        "pt_params[-5] = _pt_params[-8]\n",
        "pt_params[-4] = _pt_params[-7]\n",
        " \n",
        "for i, (tf_weight, pt_param) in enumerate(zip(tf_weights, pt_params)):\n",
        "  print(pt_param[0], tf_weight[0])\n",
        "  if len(pt_param[1].shape) == 4:\n",
        "    weight = tf_weight[1].transpose([3, 2, 0, 1])\n",
        "  elif len(pt_param[1].shape) == 2 and \\\n",
        "        pt_param[1].shape[0] == tf_weight[1].shape[1] and \\\n",
        "        pt_param[1].shape[1] == tf_weight[1].shape[0]:\n",
        "    weight = tf_weight[1].transpose([1,0])\n",
        "  else:\n",
        "    weight = tf_weight[1].reshape(pt_param[1].shape)\n",
        "  grad_status = pt_param[1].requires_grad\n",
        "  if grad_status:\n",
        "    pt_param[1].requires_grad = False\n",
        "  pt_param[1].copy_(torch.from_numpy(weight).cuda())\n",
        "  if grad_status:\n",
        "    pt_param[1].requires_grad = True\n",
        "  print(tf_weight[0], tf_weight[1].shape, pt_param[0], pt_param[1].shape)"
      ],
      "metadata": {
        "id": "C42SU8o7uAj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './pytorch_model.bin'\n",
        "torch.save(generator.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "fomRE_GZwMcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "generator.eval()\n",
        "for i in range(32):\n",
        "  x = torch.randn([1,140]).cuda()\n",
        "  y = torch.randint(0,1000,size=[1]).cuda().long()\n",
        "  y_hot = F.one_hot(y, num_classes=1000).float()\n",
        "  img = np.uint8(generator(x, y_hot).detach().cpu().numpy()[0].transpose(1,2,0).clip(0,1)*255)\n",
        "  from PIL import Image\n",
        "  display(Image.fromarray(img))"
      ],
      "metadata": {
        "id": "Ka8EiJ12vE9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Model to HuggingFace Models"
      ],
      "metadata": {
        "id": "WfSkdpx6IrWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers > /dev/null\n",
        "!apt-get install git-lfs -y"
      ],
      "metadata": {
        "id": "t9Z2zUJMIxdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store\n",
        "!git config --global user.email \"HighCWu@163.com\"\n",
        "!git config --global user.name \"HighCWu\""
      ],
      "metadata": {
        "id": "oiDGPAkAI1-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "US9_ySFpI3w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli repo create anime-biggan-pytorch"
      ],
      "metadata": {
        "id": "-fwpo1HyI4Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install"
      ],
      "metadata": {
        "id": "_3fSMWEJJDYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/HighCWu/anime-biggan-pytorch\n",
        "!cp pytorch_model.bin anime-biggan-pytorch/"
      ],
      "metadata": {
        "id": "1jrmgRHGJGlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd anime-biggan-pytorch && git lfs install\n",
        "!cd anime-biggan-pytorch && git lfs track \"*.bin\" \"*.pkl\" \"*.pth\""
      ],
      "metadata": {
        "id": "bxXUJkufJIRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd anime-biggan-pytorch && git add .\n",
        "!cd anime-biggan-pytorch && git commit -m \"First model version\""
      ],
      "metadata": {
        "id": "NOT_XIKOJW-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd anime-biggan-pytorch && git push"
      ],
      "metadata": {
        "id": "S5ssTFjrJaxL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}